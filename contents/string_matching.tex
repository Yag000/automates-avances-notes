\section{String matching}

\begin{definition}
	Étant donné deux chaines de caractères, $T$ le texte et $M$ le motif, on dit que $T$ présente une occurrence de $M$ si
	$$ \exists i, 0 \leq i \leq \len T - \len M, \forall j \in \enum 1 {\len M -1}, T[i + j] = M[j]$$
\end{definition}

\begin{remarque}
	Le texte $T$ contient le facteur $u$ \ssi $T$ a un préfixe qui appartient à $\mots u$.
\end{remarque}

\begin{remarque}
	L'algorithme trivial qui teste toutes les positions de $T$ et vérifie s'il y a une occurrence de $u$ en position $i$ est en $O(\abs T \abs u)$.

	\begin{algorithmic}[lines]
		\Function{Naif}{$T,u$}
		\For{$i$ in $0, \ldots , \len T - \len u + 1$}
		\State $j = 0$
		\While  {$j  <  \len u \et (u[j] == t[i+j])$}
		\State j ++
		\EndWhile
		\If {$j == \abs u$}
		\State Afficher l'occurrence de $u$ en position $i$
		\EndIf
		\EndFor
		\EndFunction
	\end{algorithmic}
\end{remarque}

\begin{remarque}(Un premier algorithme meilleur que le naïf)
	Pour chercher les occurrences de $u$ dans $T$, on peut construire un automate qui reconnait $\mots u$ et lui faire analyser $T$.
	À chaque fois qu'on passe par un état final, on vient de voir une occurrence de $M$.
\end{remarque}

\begin{remarque}
	Avec l'algorithme naïf, chaque caractère de $T$ pourrait être analysé $\abs u$ fois, car le motif est décalé d'une position à chaque fois.
	Avec les automates, chaque caractère est analysé une seule fois, ce qui explique l'amélioration.
\end{remarque}

\begin{remarque}
	L'approche par automates présente cependant quelques problèmes d'efficacité :
	\begin{itemize}
		\item Si l'automate est non déterministe, le temps de calcul peut devenir très lourd : il faut analyser un nombre potentiellement exponentiel de chemins.
		\item Si on le "déterminise" avant, alors on risque de trouver un automate de taille exponentielle.
	\end{itemize}
\end{remarque}

\subsection{Knuth-Morris-Pratt}


L'algorithme Knuth-Morris-Pratt, \cite{kmp}, améliore l'algorithme naïf en introduisant des décalages d'amplitude
$> 1$ et fait en sorte que chaque caractère de $T$ soit analysé une seule fois.

\begin{definition}
	Si $w$ est un mot, on appelle ""bord"" de $w$ le mot le plus long qui est en même temps préfixe et suffixe propre de $w$ .
\end{definition}

\begin{exemple}
	\quotes A et  \quotes{ABA} sont les "bords" de \quotes{ABABA}.
\end{exemple}


Pour tout mot $w \in \mots$, on note $\Bord w$ le plus long "bord" de $w$,
\cad le plus long préfixe propre de  $w$ qui est aussi un suffixe propre de $w$.
On note également $b(w)$ la longueur de $\Bord w$. De plus, pour tout $j$ tel que
$0 \leq j \leq \len w $, on note $w_j$ le préfixe de $w$ de longueur $j$.

La fonction KMP repose sur le calcul préalable de $\Bord{w_j}$ et  $b(w_j)$ pour tous les
$j$, dans un temps polynomial en $\len w$. Cette phase de prétraitement permet d’optimiser les décalages
à effectuer lors de la recherche d’un motif $u$ dans un texte $T$.

Supposons qu’au cours de la recherche de $u$ dans $T$, un échec se produit au niveau de la position $j$
du motif $u$ alors que l'on examine le texte à partir de la position $i$. Cet échec indique que le caractère
$T[i+j]$ ne correspond pas à $u[j]$.

Pour déterminer le prochain décalage efficace de $u$, on observe que :
\begin{itemize}
	\item Décaler $u$ d’une amplitude $k$, $1 \leq k \leq j$, n’a de sens que si, après ce décalage,
	      un préfixe de $u$ peut s’aligner avec la portion correspondante de $T$.
	\item Il est inutile de considérer des décalages $k < b(u_{j-1})$, car $\Bord{u_{j-1}}$
	      est précisément le plus long suffixe de $u_{j-1}$ qui est aussi un préfixe de $u$.
\end{itemize}

Ainsi, après un échec à la position $j$, le décalage optimal consiste à aligner $\Bord{u_{j-1}}$
au début de $u$ avec sa précédente occurrence dans $T$. Autrement dit, on recule le curseur
$j$ à $b(u_{j-1})$ sans avoir à comparer à nouveau les $b(u_{j-1})$ premiers caractères,
car ils sont garantis égaux en raison de la définition du "bord".

Ce mécanisme permet de limiter les comparaisons inutiles et assure que chaque caractère de $T$
est comparé à un nombre constant de caractères de $u$ en moyenne, rendant ainsi le nombre total
de comparaisons linéaire en $\len T + \len u$.


\begin{exemple}
    \todo{explain}
	\begin{eqnarray*}
		T &=& ABABAABCBABABACAB \\
		u &=& ABABACA
	\end{eqnarray*}
\end{exemple}


L'algorithme effectue un pré-traitement dans lequel pour tout $j$ avec $0 \leq j \leq \len u - 1$
calcule le plus grand "bord" du préfixe de $u$ de longueur $j$.

\begin{exemple}
	Pour le motif \quotes{ABABACA}:

	\begin{itemize}
		\item $\Bord {\motvide} = \motvide$
		\item $\Bord A = \motvide$
		\item $\Bord {AB} = \motvide$
		\item $\Bord {ABA} = A$
		\item $\Bord {ABAB} = AB$
		\item $\Bord {ABABA} = ABA$
		\item $\Bord {ABABAC} = \motvide$
		\item $\Bord {ABABACA} = A$
	\end{itemize}
\end{exemple}

Il suffit de calculer une fonction qui à tout $j \in \enum 0 {\len u - 1}$ associe
la longueur du plus long "bord" du préfixe de longueur $j$ du motif, c'est la fonction dite préfixe.


Cet algorithme peut aussi se retrouver comme un algorithme issu des automates.

Soit $u$ le motif à chercher.

\begin{definition}
	Pour tout $w \in \mots$ on défini
	$q(w) = \setdef {\text{ le plus long } X} {X \text{ est suffixe de } w \et X \text{ est préfixe de } u}$
\end{definition}

\begin{prop}
	Soit $\congN$ la congruence de Nérode induite par le langage $\mots u$, alors
	$$ w_1 \congN w_2 \iff q(w_1) = q(w_2)$$
\end{prop}

\begin{proofI}
	\item \bimpLR \\
	Supposons $w_1 \cong w_2$ ($\forall y \in \mots, w_1y \in \mots u \iff w_2y\in \mots u$)

	Notons $z$ le plus long suffixe de $w_1$ qui est aussi préfixe de  $u$ et notons $y$ le mot $z^{-1}u$ (le mot obtenu de $u$ en effaçant $z$ au début)
	alors $w_1y$ se termine par $u$, c'est-à-dire est  dans $\Sigma^*u$.


	Le mot $y$ est le mot de longueur minimale tel que $w_1y$ se termine par $u$, car s'il existait un mot $y'$ plus court que $y$  tel que $w_1y'$
	se termine par $u$ alors $z$ ne serait pas le plus long suffixe de $w_1$ qui est aussi préfixe de $u$.


	Puisque $w_1 \cong  w_2$ on a que   $w_2y$  est  dans $\Sigma^*u$ aussi, c'est-à-dire  se termine par $u$, de plus  $y$ est aussi le mot de
	longueur minimale  tel que $w_2y$  est  dans $\Sigma^*u$. En effet  si un mot $y''$ tel que $w_2y''$  est  dans $\Sigma^*u$  existait alors
	$w_1 y''$ serait aussi dans $\Sigma^*u$  à cause de l'équivalence, en contradiction avec la minimalité de $y$.


	Il en découle que $z$ est aussi un suffixe de $w_2$ et que c'est le plus long suffixe de $w_2$ qui aussi préfixe de $u$, donc $q(w_1)=q(w_2)$.

	\item \bimpRL \\
	Supposons que $q(w_1) = q(w_2)$ et nous voulons montrer que
	$$\forall y, \quad w_1 y \in \mots u \iff w_2 y \in \mots u$$

	Ceci est trivialement vrai si $\len y \geq \len u$,
	dans ce cas

	\begin{eqnarray*}
		w_1 y \text{ se termine par } u & \text{ ssi }& y \text{ se termine par } u \\
		& \text{ ssi }& w_2y \text{ se termine par } u
	\end{eqnarray*}

	Supposons donc que $\len y < \len u$ et considérons le mot $w_1 y$

	$w_1y \in \mots u \implies \exists$ un suffixe $z$ de $w_1$ qui est préfixe de $u$ et $z$ est un suffixe de $q(w_1) = q(w_2)$
	donc $z$ est aussi un suffixe de $q(w_2)$ et en particulier il est un suffixe de $w_2 \implies w_2 y $ se décompose en
	$w_2'zy = w_2 y \in \mots u$
\end{proofI}

Cette proposition suggère une nouvelle manière pour calculer l'automate minimal pour $\mots u$

\begin{eqnarray*}
	Q  &=& \set {\text {les préfixes de } u} \\
	q_0 &=& <\motvide> \\
	F &=& \set{<u>} \\
	\delta(<v>,a) &=&  \left\{ \begin{array}{cc}
		<v \cdot a>  & \text{si } v\cdot a \text{ est un préfixe de } u \\
		q(v \cdot a) & \text{sinon }
	\end{array}\right.
\end{eqnarray*}

\begin{exemple}
	Pour le mot \quotes{ABABACA} on construit l'automate suivant : \\
	\begin{automata}
		\digraph[scale=0.50]{automateStringMatch}{
			rankdir=LR;

			node [shape=circle, style=filled, color=lightblue];
			0;
			1;
			2;
			3;
			4;
			5;
			6;

			start [shape=point];
			start -> 0;

			0 -> 0 [label="X ≠ A"];
			0 -> 1 [label="A"];

			1 -> 1 [label="A"];
			1 -> 2 [label="B"];

			2 -> 3 [label="A"];

			3 -> 4 [label="B"];
			3 -> 1 [label="A"];

			4 -> 5  [label="A"];

			5 -> 6  [label="C"];
			5 -> 4  [label="B"];
			5 -> 1  [label="A"];

			6 -> 7  [label="A"];

			7 -> 2  [label="B"];
			7 -> 1  [label="A"];

			7 [shape=doublecircle];
		}
	\end{automata}

	L'automate est complet et tout transition \quotes{manquante} va vers l'état 0.
\end{exemple}


\begin{remarque}
	Si dans cet automate on remplace les préfixes de $u$ par leur longueur, on se rend compte que cet automate
	contient la même information que la fonction préfixe.
\end{remarque}
